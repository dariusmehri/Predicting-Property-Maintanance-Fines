{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: Dummy majority score: 0.93\n",
      "\n",
      "Random Forest\n",
      "Accuracy parameters (default, default)\n",
      "Accuracy on training set: 0.98\n",
      "Accuracy on test set: 0.93\n",
      "Precision: 0.49\n",
      "Recall: 0.25\n",
      "F1: 0.33\n",
      "AUC: 0.74\n",
      "\n",
      "Random Forest changing params\n",
      "Accuracy parameters (max features:2, max depth:10)\n",
      "Accuracy on training set: 0.94\n",
      "Accuracy on test set: 0.93\n",
      "Precision: 0.89\n",
      "Recall: 0.11\n",
      "F1: 0.20\n",
      "AUC: 0.77\n",
      "\n",
      "Accuracy parameters (max features:2, max depth:12)\n",
      "Accuracy on training set: 0.94\n",
      "Accuracy on test set: 0.93\n",
      "Precision: 0.85\n",
      "Recall: 0.12\n",
      "F1: 0.20\n",
      "AUC: 0.78\n",
      "\n",
      "Accuracy parameters (max features:2, max depth:14)\n",
      "Accuracy on training set: 0.94\n",
      "Accuracy on test set: 0.93\n",
      "Precision: 0.79\n",
      "Recall: 0.13\n",
      "F1: 0.22\n",
      "AUC: 0.78\n",
      "\n",
      "Accuracy parameters (max features:2, max depth:16)\n",
      "Accuracy on training set: 0.94\n",
      "Accuracy on test set: 0.93\n",
      "Precision: 0.75\n",
      "Recall: 0.14\n",
      "F1: 0.24\n",
      "AUC: 0.78\n",
      "\n",
      "Accuracy parameters (max features:2, max depth:18)\n",
      "Accuracy on training set: 0.95\n",
      "Accuracy on test set: 0.93\n",
      "Precision: 0.68\n",
      "Recall: 0.15\n",
      "F1: 0.25\n",
      "AUC: 0.78\n",
      "\n",
      "GRADIENT BOOSTED DECISION TREES\n",
      "Gradient boosting default parameters\n",
      "Accuracy parameters (default, default)\n",
      "Accuracy on training set: 0.94\n",
      "Accuracy on test set: 0.93\n",
      "Precision: 0.94\n",
      "Recall: 0.10\n",
      "F1: 0.19\n",
      "AUC: 0.78\n",
      "\n",
      "\n",
      "Adjusting gradient boosted learning rate and depth\n",
      "Accuracy parameters (learning rate:0.01, maximum depth:2)\n",
      "Accuracy on training set: 0.93\n",
      "Accuracy on test set: 0.93\n",
      "Precision: 0.95\n",
      "Recall: 0.09\n",
      "F1: 0.16\n",
      "AUC: 0.75\n",
      "\n",
      "Accuracy parameters (learning rate:0.01, maximum depth:4)\n",
      "Accuracy on training set: 0.94\n",
      "Accuracy on test set: 0.93\n",
      "Precision: 0.95\n",
      "Recall: 0.10\n",
      "F1: 0.18\n",
      "AUC: 0.76\n",
      "\n",
      "Accuracy parameters (learning rate:0.01, maximum depth:6)\n",
      "Accuracy on training set: 0.94\n",
      "Accuracy on test set: 0.93\n",
      "Precision: 0.95\n",
      "Recall: 0.10\n",
      "F1: 0.18\n",
      "AUC: 0.77\n",
      "\n",
      "Accuracy parameters (learning rate:0.1, maximum depth:2)\n",
      "Accuracy on training set: 0.94\n",
      "Accuracy on test set: 0.93\n",
      "Precision: 0.94\n",
      "Recall: 0.10\n",
      "F1: 0.18\n",
      "AUC: 0.77\n",
      "\n",
      "Accuracy parameters (learning rate:0.1, maximum depth:4)\n",
      "Accuracy on training set: 0.94\n",
      "Accuracy on test set: 0.93\n",
      "Precision: 0.91\n",
      "Recall: 0.10\n",
      "F1: 0.19\n",
      "AUC: 0.78\n",
      "\n",
      "Accuracy parameters (learning rate:0.1, maximum depth:6)\n",
      "Accuracy on training set: 0.94\n",
      "Accuracy on test set: 0.94\n",
      "Precision: 0.88\n",
      "Recall: 0.12\n",
      "F1: 0.21\n",
      "AUC: 0.78\n",
      "\n",
      "Accuracy parameters (learning rate:1, maximum depth:2)\n",
      "Accuracy on training set: 0.93\n",
      "Accuracy on test set: 0.93\n",
      "Precision: 0.93\n",
      "Recall: 0.01\n",
      "F1: 0.03\n",
      "AUC: 0.68\n",
      "\n",
      "Accuracy parameters (learning rate:1, maximum depth:4)\n",
      "Accuracy on training set: 0.93\n",
      "Accuracy on test set: 0.93\n",
      "Precision: 0.40\n",
      "Recall: 0.06\n",
      "F1: 0.10\n",
      "AUC: 0.69\n",
      "\n",
      "Accuracy parameters (learning rate:1, maximum depth:6)\n",
      "Accuracy on training set: 0.94\n",
      "Accuracy on test set: 0.92\n",
      "Precision: 0.42\n",
      "Recall: 0.15\n",
      "F1: 0.22\n",
      "AUC: 0.72\n",
      "\n",
      "\n",
      "LOGISTIC REGRESSION\n",
      "Default parameters\n",
      "Accuracy parameters (default, default)\n",
      "Accuracy on training set: 0.93\n",
      "Accuracy on test set: 0.93\n",
      "Precision: 0.81\n",
      "Recall: 0.10\n",
      "F1: 0.17\n",
      "AUC: 0.75\n",
      "\n",
      "\n",
      "Varying regularization c parameter\n",
      "Accuracy parameters (C reg param:0.1, none)\n",
      "Accuracy on training set: 0.93\n",
      "Accuracy on test set: 0.93\n",
      "Precision: 0.81\n",
      "Recall: 0.10\n",
      "F1: 0.17\n",
      "AUC: 0.75\n",
      "\n",
      "Accuracy parameters (C reg param:1, none)\n",
      "Accuracy on training set: 0.93\n",
      "Accuracy on test set: 0.93\n",
      "Precision: 0.81\n",
      "Recall: 0.10\n",
      "F1: 0.17\n",
      "AUC: 0.75\n",
      "\n",
      "Accuracy parameters (C reg param:100, none)\n",
      "Accuracy on training set: 0.93\n",
      "Accuracy on test set: 0.93\n",
      "Precision: 0.81\n",
      "Recall: 0.10\n",
      "F1: 0.17\n",
      "AUC: 0.75\n",
      "\n",
      "\n",
      "KNN\n",
      "Accuracy parameters (none, none)\n",
      "Accuracy on training set: 0.94\n",
      "Accuracy on test set: 0.93\n",
      "Precision: 0.53\n",
      "Recall: 0.19\n",
      "F1: 0.28\n",
      "AUC: 0.72\n",
      "\n",
      "\n",
      "KNN with MinMax Scaling\n",
      "Accuracy parameters (MinMax Scaled, none)\n",
      "Accuracy on training set: 0.93\n",
      "Accuracy on test set: 0.93\n",
      "Precision: 0.52\n",
      "Recall: 0.19\n",
      "F1: 0.28\n",
      "AUC: 0.72\n",
      "\n",
      "\n",
      "NAIVE BAYES\n",
      "Accuracy parameters (default, default)\n",
      "Accuracy on training set: 0.93\n",
      "Accuracy on test set: 0.93\n",
      "Precision: 0.95\n",
      "Recall: 0.09\n",
      "F1: 0.16\n",
      "AUC: 0.66\n",
      "\n",
      "\n",
      "SUPPORT VECTOR MACHINES\n",
      "SVM with RBF kernal and grid search optimizing for AUC\n",
      "Test set AUC:  0.7564098919872628\n",
      "Grid best parameter (max. AUC):  {'gamma': 0.001}\n",
      "Grid best score (AUC):  0.695394931299781\n"
     ]
    }
   ],
   "source": [
    "path = \"C:\\\\Users\\\\dmehri\\\\Documents\\\\DATA\\\\\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def blight_model():\n",
    "    \n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    #from adspy_shared_utilities import plot_class_regions_for_classifier_subplot\n",
    "    #create data\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.datasets import make_classification, make_blobs\n",
    "    from sklearn.dummy import DummyClassifier\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    \n",
    "      \n",
    "        \n",
    "    test = pd.read_csv(path + \"test.csv\")\n",
    "    train = pd.read_csv(path + \"train.csv\",encoding = 'ISO-8859-1',low_memory=False )\n",
    "    address = pd.read_csv(path + \"addresses.csv\",low_memory=False )\n",
    "    latlon = pd.read_csv(path + \"latlons.csv\",low_memory=False )\n",
    "    \n",
    "    \n",
    "    #DROP NAs\n",
    "    #print (\"len before drop NA\", len(train) )\n",
    "    train = train.dropna(subset = ['compliance']).reset_index(drop=True)\n",
    "    #print ( \"len after drop NA\", len(train) )\n",
    "    #print (\"len of test dataset\", len(test))\n",
    "    \n",
    "    #print (\"Count the class labels\")\n",
    "    #print (\"Compliance\")\n",
    "    #print  ( (train[\"compliance\"]==1).sum() )\n",
    "    #print (\"No compliance\")\n",
    "    #print ( (train[\"compliance\"]==0).sum() )\n",
    "    #print \n",
    "    \n",
    "    def CleanAndTransformData(df):\n",
    "        #REMOVE FEATURES\n",
    "        #DROP DATES\n",
    "        df = df.drop('hearing_date', 1)\n",
    "        df = df.drop('ticket_issued_date', 1)\n",
    "        #ADDRESS    \n",
    "        df = df.drop('mailing_address_str_number', 1)\n",
    "        df = df.drop('mailing_address_str_name', 1)\n",
    "        df = df.drop('city', 1)\n",
    "        df = df.drop('state', 1)\n",
    "        df = df.drop('zip_code', 1)\n",
    "        df = df.drop('non_us_str_code', 1)\n",
    "        df = df.drop('country', 1)\n",
    "        df = df.drop('violator_name', 1)\n",
    "        df = df.drop('violation_street_number', 1)\n",
    "        df = df.drop('violation_street_name', 1)\n",
    "        #DROP ASSORTED\n",
    "        df = df.drop('inspector_name', 1)\n",
    "        df = df.drop('violation_zip_code', 1)\n",
    "        df = df.drop('clean_up_cost', 1)\n",
    "        df = df.drop('admin_fee', 1)\n",
    "        df = df.drop('state_fee', 1)\n",
    "        df = df.drop('grafitti_status', 1)\n",
    "        #PERHAPS TOO MANY CATEGORIES\n",
    "        df = df.drop('violation_code', 1)\n",
    "        df = df.drop('violation_description', 1)\n",
    "        #CATEGORIES DON'T MATCH WITH TEST DATA\n",
    "        df = df.drop('agency_name', 1)\n",
    "        df = df.drop('disposition', 1)\n",
    "\n",
    "        #ADD FEATURES\n",
    "        #INSERT LAT/LON\n",
    "        lat = latlon.set_index('address')['lat'].to_dict()\n",
    "        lon = latlon.set_index('address')['lon'].to_dict()\n",
    "        address[\"lat\"] = address[\"address\"].map(lat)\n",
    "        address[\"lon\"] = address[\"address\"].map(lon)\n",
    "        lat = address.set_index('ticket_id')['lat'].to_dict()\n",
    "        lon = address.set_index('ticket_id')['lon'].to_dict()\n",
    "        #map lat/lon to dfing dataset\n",
    "        df[\"lat\"] = df[\"ticket_id\"].map(lat)\n",
    "        df[\"lon\"] = df[\"ticket_id\"].map(lon)   \n",
    "        \n",
    "        return df\n",
    "\n",
    "  \n",
    "    train = CleanAndTransformData(train)\n",
    "    test = CleanAndTransformData(test)\n",
    "\n",
    "    #FEATURES NOT IN TEST DATA\n",
    "    train = train.drop('payment_amount', 1)\n",
    "    train = train.drop('payment_date', 1)\n",
    "    train = train.drop('payment_status', 1)\n",
    "    train = train.drop('balance_due', 1)\n",
    "    train = train.drop('collection_status', 1)\n",
    "    train = train.drop('compliance_detail', 1)\n",
    "    \n",
    "    #CREATE MODEL\n",
    "    #train = train.drop('ticket_id', 1)\n",
    "    \n",
    "    model_selection = []\n",
    "    \n",
    "    def AccuracyAndAUC(model, clf, X_test, y_test, a, b):\n",
    "        a = \"(\" + a + \",\"\n",
    "        b = b + \")\"\n",
    "        accuracy_param = a + b\n",
    "        clf_predicted = clf.predict(X_test)\n",
    "        print (\"Accuracy parameters\", a, b)\n",
    "        print('Accuracy on training set: {:.2f}'.format(clf.score(X_train, y_train)))\n",
    "        print('Accuracy on test set: {:.2f}'.format(accuracy_score(y_test, clf_predicted)))\n",
    "        print('Precision: {:.2f}'.format(precision_score(y_test, clf_predicted)))\n",
    "        print('Recall: {:.2f}'.format(recall_score(y_test, clf_predicted)))\n",
    "        print('F1: {:.2f}'.format(f1_score(y_test, clf_predicted)))\n",
    "    \n",
    "        #print(classification_report(y_test, clf_predicted, target_names=['not 1', '1']))\n",
    "        \n",
    "        #y_score_gb = clf.fit(X_train, y_train).decision_function(X_test)\n",
    "        #fpr_lr, tpr_lr, _ = roc_curve(y_test, y_score_gb)\n",
    "        #roc_auc_gb = auc(fpr_lr, tpr_lr)\n",
    "        #print (\"AUC:\", round(roc_auc_gb, 2))\n",
    "        \n",
    "        pred_prob = clf.predict_proba(X_test)[:,1]\n",
    "        roc=roc_auc_score(y_test, pred_prob)\n",
    "        print ('AUC:', round(roc, 2))\n",
    "\n",
    "        \n",
    "        #clf_predicted = clf.predict(X_test)\n",
    "        #confusion = confusion_matrix(y_test, clf_predicted)\n",
    "\n",
    "        #print('Classifier Confusion Matrix\\n', confusion)\n",
    "        print()\n",
    "        \n",
    "        model_selection.append([model,accuracy_param, clf.score(X_train, y_train), accuracy_score(y_test, clf_predicted),\n",
    "                               precision_score(y_test, clf_predicted),recall_score(y_test, clf_predicted), \n",
    "                                f1_score(y_test, clf_predicted), roc])\n",
    "        \n",
    "        \n",
    "        \n",
    "    def AccuracySVM(clf, X_test, y_test, a, b):\n",
    "        a = \"(\" + a + \",\"\n",
    "        b = b + \")\"\n",
    "        clf_predicted = clf.predict(X_test)\n",
    "        print ()\n",
    "        print (\"Accuracy on these parameters\", a, b)\n",
    "        print('Accuracy on test set: {:.2f}'.format(accuracy_score(y_test, clf_predicted)))\n",
    "        print('Precision: {:.2f}'.format(precision_score(y_test, clf_predicted)))\n",
    "        print('Recall: {:.2f}'.format(recall_score(y_test, clf_predicted)))\n",
    "        print('F1: {:.2f}'.format(f1_score(y_test, clf_predicted)))\n",
    "        \n",
    "        #pred_prob = clf.predict_proba(X_test)[:,1]\n",
    "        #roc=roc_auc_score(y_test, pred_prob)\n",
    "        #print ('AUC:', round(roc, 2))\n",
    "        \n",
    "        y_score_gb = clf.fit(X_train, y_train).decision_function(X_test)\n",
    "        fpr_lr, tpr_lr, _ = roc_curve(y_test, y_score_gb)\n",
    "        roc_auc_gb = auc(fpr_lr, tpr_lr)\n",
    "        print (\"AUC:\", round(roc_auc_gb, 2))\n",
    "\n",
    "\n",
    "        clf_predicted = clf.predict(X_test)\n",
    "        confusion = confusion_matrix(y_test, clf_predicted)\n",
    "\n",
    "        print('Classifier Confusion Matrix\\n', confusion)\n",
    "        \n",
    "        \n",
    "    def PlotROC(clf, X_test, y_test):\n",
    "        y_score_gb = clf.fit(X_train, y_train).decision_function(X_test)\n",
    "        fpr_lr, tpr_lr, _ = roc_curve(y_test, y_score_gb)\n",
    "        roc_auc = auc(fpr_lr, tpr_lr)\n",
    "        #PLOT\n",
    "        plt.figure()\n",
    "        plt.xlim([-0.01, 1.00])\n",
    "        plt.ylim([-0.01, 1.01])\n",
    "        plt.plot(fpr_lr, tpr_lr, lw=3, label='ROC curve (area = {:0.2f})'.format(roc_auc))\n",
    "        plt.xlabel('False Positive Rate', fontsize=16)\n",
    "        plt.ylabel('True Positive Rate', fontsize=16)\n",
    "        plt.title('ROC curve (1-of-10 digits classifier)', fontsize=16)\n",
    "        plt.legend(loc='lower right', fontsize=13)\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=3, linestyle='--')\n",
    "        plt.axes().set_aspect('equal')\n",
    "        plt.show()\n",
    "        \n",
    "        return plt.show()\n",
    "    \n",
    "    \n",
    "    #MODEL\n",
    "    y = train[\"compliance\"]\n",
    "    X = train[[\"fine_amount\", \"late_fee\", \"discount_amount\", \"judgment_amount\", \"lat\", \"lon\"] ]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "    #fillna with mean\n",
    "    X_train = X_train.fillna(X_train.mean())\n",
    "    \n",
    "    #test baseline using dummy classifier\n",
    "    dummy_majority = DummyClassifier(strategy = 'most_frequent').fit(X_train, y_train)\n",
    "    \n",
    "    print (\"Baseline Accuracy: Dummy majority score:\", round(dummy_majority.score(X_test, y_test), 2) )\n",
    "    print ()\n",
    "    \n",
    "    #RANDOM FORESTS\n",
    "    print (\"Random Forest\")\n",
    "    clf = RandomForestClassifier(random_state = 0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    model = \"Random Forest\"\n",
    "    a = \"default\"\n",
    "    b = \"default\"\n",
    "    AccuracyAndAUC(model, clf, X_test, y_test, a, b)\n",
    "    \n",
    "    print (\"Random Forest changing params\")\n",
    "    max_depth_list = [10,12,14, 16, 18]\n",
    "    \n",
    "    #max_features = sqrt(number of features)\n",
    "    for max_d in max_depth_list:\n",
    "        clf = RandomForestClassifier(max_features = 2,max_depth = max_d, random_state = 0)\n",
    "        clf.fit(X_train, y_train)\n",
    "        a = \"max features:\" + str(2)\n",
    "        b = \"max depth:\" + str(max_d)\n",
    "        AccuracyAndAUC(model, clf, X_test, y_test, a, b)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #GRADIENT BOOSTED DECISION TREES\n",
    "    print (\"GRADIENT BOOSTED DECISION TREES\")\n",
    "    print (\"Gradient boosting default parameters\")\n",
    "    clf = GradientBoostingClassifier(random_state = 0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    model = \"Gradient Boosted Dec Trees\"\n",
    "    a = \"default\"\n",
    "    b = \"default\"\n",
    "    AccuracyAndAUC(model, clf, X_test, y_test, a, b)\n",
    "    #PlotROC(clf, X_test, y_test)\n",
    "    \n",
    "    print ()\n",
    "    print (\"Adjusting gradient boosted learning rate and depth\")\n",
    "    learn_rate = [0.01, 0.1, 1]\n",
    "    max_depth = [2,4,6]\n",
    "    \n",
    "    for learn in learn_rate:\n",
    "        for depth in max_depth:\n",
    "            clf = GradientBoostingClassifier(learning_rate = learn, max_depth = depth, random_state = 0)\n",
    "            clf.fit(X_train, y_train)\n",
    "            a = \"learning rate:\" + str(learn)\n",
    "            b = \"maximum depth:\" + str(depth)\n",
    "            AccuracyAndAUC(model, clf, X_test, y_test, a, b)\n",
    "            \n",
    "\n",
    "         \n",
    "    #LOGISTIC REGRESSION\n",
    "    print ()\n",
    "    print (\"LOGISTIC REGRESSION\")\n",
    "    print (\"Default parameters\")\n",
    "    clf = LogisticRegression().fit(X_train, y_train)\n",
    "    clf.fit(X_train, y_train)\n",
    "    model = \"Logistic Regression\"\n",
    "    a = \"default\"\n",
    "    b = \"default\"\n",
    "    AccuracyAndAUC(model, clf, X_test, y_test, a, b)\n",
    "    \n",
    "    print ()\n",
    "    print (\"Varying regularization c parameter\")\n",
    "    this_C_list = [0.1, 1, 100]\n",
    "    b = \"none\"\n",
    "    for this_C in this_C_list:\n",
    "        a = \"C reg param:\" + str(this_C)\n",
    "        clf = LogisticRegression(C=this_C).fit(X_train, y_train)\n",
    "        AccuracyAndAUC(model, clf, X_test, y_test, a, b)\n",
    "    \n",
    "    \n",
    "    #K-NEAREST NEIGHBORS\n",
    "    print ()\n",
    "    print (\"KNN\")\n",
    "    clf = KNeighborsClassifier(n_neighbors = 5)\n",
    "    clf.fit(X_train, y_train)\n",
    "    model = \"KNN\"\n",
    "    a = \"none\"\n",
    "    b = \"none\"\n",
    "    AccuracyAndAUC(model, clf, X_test, y_test, a, b)\n",
    "    \n",
    "    print()\n",
    "    print (\"KNN with MinMax Scaling\")\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    # we must apply the scaling to the test set that we computed for the training set\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    clf = KNeighborsClassifier(n_neighbors = 5)\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    a = \"MinMax Scaled\"\n",
    "    b = \"none\"\n",
    "    AccuracyAndAUC(model, clf, X_test_scaled, y_test, a, b)\n",
    "    \n",
    "\n",
    "    #NAIVE BAYES\n",
    "    print ()\n",
    "    print (\"NAIVE BAYES\")\n",
    "    clf = GaussianNB().fit(X_train, y_train)\n",
    "    model = \"Naive Bayes\"\n",
    "    a = \"default\"\n",
    "    b = \"default\"\n",
    "    AccuracyAndAUC(model, clf, X_test, y_test, a, b)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    #SVM\n",
    "    print (\"SUPPORT VECTOR MACHINES\")\n",
    "    #print (\"With default RBF Kernal and MinMax Scaling\")\n",
    "    model = \"SVM\"\n",
    "    a = \"MinMax Scalaing\"\n",
    "    b = \"Grid Search\"\n",
    "    accuracy_param = \"(\" + a + \",\" + b + \")\"\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    #clf = SVC(random_state = 0)\n",
    "    #clf.fit(X_train_scaled, y_train)\n",
    "    #AccuracySVM(clf, X_test_scaled, y_test, a, b)\n",
    "    \n",
    "    print (\"SVM with RBF kernal and grid search optimizing for AUC\")\n",
    "    \n",
    "    clf = SVC(kernel='rbf')\n",
    "    grid_values = {'gamma': [0.001, 0.01, 0.05, 0.1, 1, 10, 100]}\n",
    "    \n",
    "    grid_clf_auc = GridSearchCV(clf, param_grid = grid_values, scoring = 'roc_auc')\n",
    "    grid_clf_auc.fit(X_train_scaled, y_train)\n",
    "    y_decision_fn_scores_auc = grid_clf_auc.decision_function(X_test_scaled) \n",
    "\n",
    "    print('Test set AUC: ', roc_auc_score(y_test, y_decision_fn_scores_auc))\n",
    "    print('Grid best parameter (max. AUC): ', grid_clf_auc.best_params_)\n",
    "    print('Grid best score (AUC): ', grid_clf_auc.best_score_)\n",
    "    \n",
    "   \n",
    "        \n",
    "    model_selection.append([model,accuracy_param, \" \", grid_clf_auc.best_score_,\n",
    "                               \" \", \" \", \" \", roc_auc_score(y_test, y_decision_fn_scores_auc)])\n",
    "    \n",
    "    return model_selection\n",
    "\n",
    "df = blight_model()\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame(df, columns=('Model','Parameters', 'Training Score', 'Test Score', 'Precision', 'Recall', 'F1', 'AUC'))\n",
    "#df.to_csv(path + \"train_edit.csv\", index=False)\n",
    "\n",
    "df2 = df2.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>(default,default)</td>\n",
       "      <td>0.981553</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.486815</td>\n",
       "      <td>0.248963</td>\n",
       "      <td>0.329444</td>\n",
       "      <td>0.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>(max features:2,max depth:10)</td>\n",
       "      <td>0.936861</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.885559</td>\n",
       "      <td>0.112379</td>\n",
       "      <td>0.199448</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>(max features:2,max depth:12)</td>\n",
       "      <td>0.938145</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.847716</td>\n",
       "      <td>0.115491</td>\n",
       "      <td>0.203287</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>(max features:2,max depth:14)</td>\n",
       "      <td>0.941031</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.790598</td>\n",
       "      <td>0.127939</td>\n",
       "      <td>0.220238</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>(max features:2,max depth:16)</td>\n",
       "      <td>0.944041</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.753704</td>\n",
       "      <td>0.140733</td>\n",
       "      <td>0.237179</td>\n",
       "      <td>0.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>(max features:2,max depth:18)</td>\n",
       "      <td>0.947469</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.677761</td>\n",
       "      <td>0.15491</td>\n",
       "      <td>0.252181</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boosted Dec Trees</td>\n",
       "      <td>(default,default)</td>\n",
       "      <td>0.935794</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.940063</td>\n",
       "      <td>0.103043</td>\n",
       "      <td>0.185728</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradient Boosted Dec Trees</td>\n",
       "      <td>(learning rate:0.01,maximum depth:2)</td>\n",
       "      <td>0.934259</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.945255</td>\n",
       "      <td>0.0895574</td>\n",
       "      <td>0.163613</td>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gradient Boosted Dec Trees</td>\n",
       "      <td>(learning rate:0.01,maximum depth:4)</td>\n",
       "      <td>0.935643</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.95098</td>\n",
       "      <td>0.100622</td>\n",
       "      <td>0.181989</td>\n",
       "      <td>0.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gradient Boosted Dec Trees</td>\n",
       "      <td>(learning rate:0.01,maximum depth:6)</td>\n",
       "      <td>0.935718</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.950495</td>\n",
       "      <td>0.0995851</td>\n",
       "      <td>0.180282</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gradient Boosted Dec Trees</td>\n",
       "      <td>(learning rate:0.1,maximum depth:2)</td>\n",
       "      <td>0.935668</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.942122</td>\n",
       "      <td>0.101314</td>\n",
       "      <td>0.182953</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Gradient Boosted Dec Trees</td>\n",
       "      <td>(learning rate:0.1,maximum depth:4)</td>\n",
       "      <td>0.936261</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.914373</td>\n",
       "      <td>0.103389</td>\n",
       "      <td>0.185772</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Gradient Boosted Dec Trees</td>\n",
       "      <td>(learning rate:0.1,maximum depth:6)</td>\n",
       "      <td>0.93792</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.879487</td>\n",
       "      <td>0.118603</td>\n",
       "      <td>0.209019</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gradient Boosted Dec Trees</td>\n",
       "      <td>(learning rate:1,maximum depth:2)</td>\n",
       "      <td>0.928847</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.0127939</td>\n",
       "      <td>0.0252387</td>\n",
       "      <td>0.682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gradient Boosted Dec Trees</td>\n",
       "      <td>(learning rate:1,maximum depth:4)</td>\n",
       "      <td>0.931674</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.395238</td>\n",
       "      <td>0.0573997</td>\n",
       "      <td>0.100242</td>\n",
       "      <td>0.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Gradient Boosted Dec Trees</td>\n",
       "      <td>(learning rate:1,maximum depth:6)</td>\n",
       "      <td>0.940947</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.421206</td>\n",
       "      <td>0.149723</td>\n",
       "      <td>0.220918</td>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>(default,default)</td>\n",
       "      <td>0.934201</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.0954357</td>\n",
       "      <td>0.170792</td>\n",
       "      <td>0.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>(C reg param:0.1,none)</td>\n",
       "      <td>0.934201</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.0954357</td>\n",
       "      <td>0.170792</td>\n",
       "      <td>0.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>(C reg param:1,none)</td>\n",
       "      <td>0.934201</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.0954357</td>\n",
       "      <td>0.170792</td>\n",
       "      <td>0.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>(C reg param:100,none)</td>\n",
       "      <td>0.934201</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.0954357</td>\n",
       "      <td>0.170792</td>\n",
       "      <td>0.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>KNN</td>\n",
       "      <td>(none,none)</td>\n",
       "      <td>0.942774</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.52671</td>\n",
       "      <td>0.194329</td>\n",
       "      <td>0.28391</td>\n",
       "      <td>0.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>KNN</td>\n",
       "      <td>(MinMax Scaled,none)</td>\n",
       "      <td>0.927404</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.524209</td>\n",
       "      <td>0.194675</td>\n",
       "      <td>0.283913</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>(default,default)</td>\n",
       "      <td>0.934242</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.945255</td>\n",
       "      <td>0.0895574</td>\n",
       "      <td>0.163613</td>\n",
       "      <td>0.664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SVM</td>\n",
       "      <td>(MinMax Scalaing,Grid Search)</td>\n",
       "      <td></td>\n",
       "      <td>0.695</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model                            Parameters  \\\n",
       "0                Random Forest                     (default,default)   \n",
       "1                Random Forest         (max features:2,max depth:10)   \n",
       "2                Random Forest         (max features:2,max depth:12)   \n",
       "3                Random Forest         (max features:2,max depth:14)   \n",
       "4                Random Forest         (max features:2,max depth:16)   \n",
       "5                Random Forest         (max features:2,max depth:18)   \n",
       "6   Gradient Boosted Dec Trees                     (default,default)   \n",
       "7   Gradient Boosted Dec Trees  (learning rate:0.01,maximum depth:2)   \n",
       "8   Gradient Boosted Dec Trees  (learning rate:0.01,maximum depth:4)   \n",
       "9   Gradient Boosted Dec Trees  (learning rate:0.01,maximum depth:6)   \n",
       "10  Gradient Boosted Dec Trees   (learning rate:0.1,maximum depth:2)   \n",
       "11  Gradient Boosted Dec Trees   (learning rate:0.1,maximum depth:4)   \n",
       "12  Gradient Boosted Dec Trees   (learning rate:0.1,maximum depth:6)   \n",
       "13  Gradient Boosted Dec Trees     (learning rate:1,maximum depth:2)   \n",
       "14  Gradient Boosted Dec Trees     (learning rate:1,maximum depth:4)   \n",
       "15  Gradient Boosted Dec Trees     (learning rate:1,maximum depth:6)   \n",
       "16         Logistic Regression                     (default,default)   \n",
       "17         Logistic Regression                (C reg param:0.1,none)   \n",
       "18         Logistic Regression                  (C reg param:1,none)   \n",
       "19         Logistic Regression                (C reg param:100,none)   \n",
       "20                         KNN                           (none,none)   \n",
       "21                         KNN                  (MinMax Scaled,none)   \n",
       "22                 Naive Bayes                     (default,default)   \n",
       "23                         SVM         (MinMax Scalaing,Grid Search)   \n",
       "\n",
       "   Training Score  Test Score Precision     Recall         F1    AUC  \n",
       "0        0.981553       0.927  0.486815   0.248963   0.329444  0.739  \n",
       "1        0.936861       0.935  0.885559   0.112379   0.199448  0.775  \n",
       "2        0.938145       0.935  0.847716   0.115491   0.203287  0.778  \n",
       "3        0.941031       0.934  0.790598   0.127939   0.220238  0.778  \n",
       "4        0.944041       0.935  0.753704   0.140733   0.237179  0.777  \n",
       "5        0.947469       0.934  0.677761    0.15491   0.252181  0.776  \n",
       "6        0.935794       0.935  0.940063   0.103043   0.185728  0.775  \n",
       "7        0.934259       0.934  0.945255  0.0895574   0.163613  0.753  \n",
       "8        0.935643       0.935   0.95098   0.100622   0.181989  0.765  \n",
       "9        0.935718       0.934  0.950495  0.0995851   0.180282  0.770  \n",
       "10       0.935668       0.935  0.942122   0.101314   0.182953  0.771  \n",
       "11       0.936261       0.934  0.914373   0.103389   0.185772  0.776  \n",
       "12        0.93792       0.935  0.879487   0.118603   0.209019  0.782  \n",
       "13       0.928847       0.928     0.925  0.0127939  0.0252387  0.682  \n",
       "14       0.931674       0.925  0.395238  0.0573997   0.100242  0.688  \n",
       "15       0.940947       0.924  0.421206   0.149723   0.220918  0.718  \n",
       "16       0.934201       0.933  0.811765  0.0954357   0.170792  0.751  \n",
       "17       0.934201       0.933  0.811765  0.0954357   0.170792  0.751  \n",
       "18       0.934201       0.933  0.811765  0.0954357   0.170792  0.751  \n",
       "19       0.934201       0.933  0.811765  0.0954357   0.170792  0.751  \n",
       "20       0.942774       0.929   0.52671   0.194329    0.28391  0.722  \n",
       "21       0.927404       0.929  0.524209   0.194675   0.283913  0.723  \n",
       "22       0.934242       0.934  0.945255  0.0895574   0.163613  0.664  \n",
       "23                      0.695                                  0.756  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticket_id\n",
       "284932    0.049604\n",
       "285362    0.019340\n",
       "285361    0.058237\n",
       "285338    0.062403\n",
       "285346    0.059115\n",
       "285345    0.056676\n",
       "285347    0.073064\n",
       "285342    0.328722\n",
       "285530    0.047118\n",
       "284989    0.029101\n",
       "285344    0.063772\n",
       "285343    0.027744\n",
       "285340    0.029927\n",
       "285341    0.089976\n",
       "285349    0.071354\n",
       "285348    0.068447\n",
       "284991    0.029101\n",
       "285532    0.039008\n",
       "285406    0.028859\n",
       "285001    0.067540\n",
       "285006    0.052894\n",
       "285405    0.018862\n",
       "285337    0.026078\n",
       "285496    0.051573\n",
       "285497    0.056117\n",
       "285378    0.022079\n",
       "285589    0.023427\n",
       "285585    0.051283\n",
       "285501    0.068152\n",
       "285581    0.029104\n",
       "            ...   \n",
       "376367    0.029976\n",
       "376366    0.034358\n",
       "376362    0.035630\n",
       "376363    0.058806\n",
       "376365    0.029976\n",
       "376364    0.034358\n",
       "376228    0.109724\n",
       "376265    0.035357\n",
       "376286    0.314782\n",
       "376320    0.029752\n",
       "376314    0.026631\n",
       "376327    0.379298\n",
       "376385    0.342050\n",
       "376435    0.553965\n",
       "376370    0.345206\n",
       "376434    0.052685\n",
       "376459    0.076020\n",
       "376478    0.007080\n",
       "376473    0.033018\n",
       "376484    0.034101\n",
       "376482    0.034788\n",
       "376480    0.034788\n",
       "376479    0.034788\n",
       "376481    0.034788\n",
       "376483    0.043567\n",
       "376496    0.020798\n",
       "376497    0.020798\n",
       "376499    0.057828\n",
       "376500    0.057828\n",
       "369851    0.215944\n",
       "Length: 61001, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def best_model():\n",
    "    \n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    \n",
    "    test = pd.read_csv(path + \"test.csv\")\n",
    "    train = pd.read_csv(path + \"train.csv\",encoding = 'ISO-8859-1',low_memory=False )\n",
    "    address = pd.read_csv(path + \"addresses.csv\",low_memory=False )\n",
    "    latlon = pd.read_csv(path + \"latlons.csv\",low_memory=False )\n",
    "    \n",
    "    \n",
    "    #DROP NAs\n",
    "    #print (\"len before drop NA\", len(train) )\n",
    "    train = train.dropna(subset = ['compliance']).reset_index(drop=True)\n",
    "    \n",
    "    def CleanAndTransformData(df):\n",
    "        #REMOVE FEATURES\n",
    "        #DROP DATES\n",
    "        df = df.drop('hearing_date', 1)\n",
    "        df = df.drop('ticket_issued_date', 1)\n",
    "        #ADDRESS    \n",
    "        df = df.drop('mailing_address_str_number', 1)\n",
    "        df = df.drop('mailing_address_str_name', 1)\n",
    "        df = df.drop('city', 1)\n",
    "        df = df.drop('state', 1)\n",
    "        df = df.drop('zip_code', 1)\n",
    "        df = df.drop('non_us_str_code', 1)\n",
    "        df = df.drop('country', 1)\n",
    "        df = df.drop('violator_name', 1)\n",
    "        df = df.drop('violation_street_number', 1)\n",
    "        df = df.drop('violation_street_name', 1)\n",
    "        #DROP ASSORTED\n",
    "        df = df.drop('inspector_name', 1)\n",
    "        df = df.drop('violation_zip_code', 1)\n",
    "        df = df.drop('clean_up_cost', 1)\n",
    "        df = df.drop('admin_fee', 1)\n",
    "        df = df.drop('state_fee', 1)\n",
    "        df = df.drop('grafitti_status', 1)\n",
    "        #PERHAPS TOO MANY CATEGORIES\n",
    "        df = df.drop('violation_code', 1)\n",
    "        df = df.drop('violation_description', 1)\n",
    "        #CATEGORIES DON'T MATCH WITH TEST DATA\n",
    "        df = df.drop('agency_name', 1)\n",
    "        df = df.drop('disposition', 1)\n",
    "\n",
    "        #ADD FEATURES\n",
    "        #INSERT LAT/LON\n",
    "        lat = latlon.set_index('address')['lat'].to_dict()\n",
    "        lon = latlon.set_index('address')['lon'].to_dict()\n",
    "        address[\"lat\"] = address[\"address\"].map(lat)\n",
    "        address[\"lon\"] = address[\"address\"].map(lon)\n",
    "        lat = address.set_index('ticket_id')['lat'].to_dict()\n",
    "        lon = address.set_index('ticket_id')['lon'].to_dict()\n",
    "        #map lat/lon to dfing dataset\n",
    "        df[\"lat\"] = df[\"ticket_id\"].map(lat)\n",
    "        df[\"lon\"] = df[\"ticket_id\"].map(lon)\n",
    "        \n",
    "      \n",
    "        return df\n",
    "    \n",
    "    #clean and transform data\n",
    "    train = CleanAndTransformData(train)\n",
    "    test = CleanAndTransformData(test)\n",
    "\n",
    "    #FEATURES NOT IN TEST DATA\n",
    "    train = train.drop('payment_amount', 1)\n",
    "    train = train.drop('payment_date', 1)\n",
    "    train = train.drop('payment_status', 1)\n",
    "    train = train.drop('balance_due', 1)\n",
    "    train = train.drop('collection_status', 1)\n",
    "    train = train.drop('compliance_detail', 1)\n",
    "    \n",
    "    #TRAIN AND TEST THE MODEL\n",
    "    y_train = train[\"compliance\"]\n",
    "    X_train = train[[\"fine_amount\", \"late_fee\", \"discount_amount\", \"judgment_amount\", \"lat\", \"lon\"] ]\n",
    "    #fillna with mean\n",
    "    X_train = X_train.fillna(X_train.mean())\n",
    "    \n",
    "    X_test = test[[\"fine_amount\", \"late_fee\", \"discount_amount\", \"judgment_amount\", \"lat\", \"lon\"] ]\n",
    "\n",
    "    \n",
    "    clf = GradientBoostingClassifier(learning_rate = 0.1, max_depth = 6, random_state = 0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    X_test = X_test.fillna(X_test.mean())\n",
    "    \n",
    "    result  =   clf.predict_proba(X_test)\n",
    "    \n",
    "    #assign positive class probability predictions\n",
    "    test[\"PredProb\"] = result[:,1]\n",
    "\n",
    "    \n",
    "    test_out = test[[\"ticket_id\", \"PredProb\"]] \n",
    "    \n",
    "    test_out_series = pd.Series(test_out['PredProb'].values, index=test_out['ticket_id'])\n",
    "    \n",
    "    return test_out_series\n",
    "\n",
    "\n",
    "best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
